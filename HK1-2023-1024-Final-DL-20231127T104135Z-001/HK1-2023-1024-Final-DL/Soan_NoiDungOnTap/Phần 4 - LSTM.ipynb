{"cells":[{"cell_type":"markdown","metadata":{},"source":["```\n","tf.keras.layers.LSTM(\n","    units,\n","    activation=\"tanh\",\n","    recurrent_activation=\"sigmoid\",\n","    use_bias=True,\n","    kernel_initializer=\"glorot_uniform\",\n","    recurrent_initializer=\"orthogonal\",\n","    bias_initializer=\"zeros\",\n","    unit_forget_bias=True,\n","    kernel_regularizer=None,\n","    recurrent_regularizer=None,\n","    bias_regularizer=None,\n","    activity_regularizer=None,\n","    kernel_constraint=None,\n","    recurrent_constraint=None,\n","    bias_constraint=None,\n","    dropout=0.0,\n","    recurrent_dropout=0.0,\n","    return_sequences=False,\n","    return_state=False,\n","    go_backwards=False,\n","    stateful=False,\n","    time_major=False,\n","    unroll=False,\n","    **kwargs\n",")\n","```"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# type: ignore\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input , Dense , LSTM , Embedding , Dropout , add, Conv2D, TimeDistributed"]},{"cell_type":"markdown","metadata":{"id":"8AsolnVSiDmM"},"source":["# Formula to calculate the number of parameters of LSTM"]},{"cell_type":"markdown","metadata":{"id":"oS8nNjihn4d7"},"source":["The formula for trainable parameter in the LSTM layer is is\n","\n","$4*(n+m+1)*m$\n","\n","**n** is the dimension of the input vector\n","\n","**m** is the number of LSTM units in a layer\n","\n","**1** is the bias parameter\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3932,"status":"ok","timestamp":1700681749158,"user":{"displayName":"Nhữ Hùng Huỳnh","userId":"01101641021220608093"},"user_tz":-420},"id":"zfAUriX5iAfu","outputId":"ceb31974-998c-4f34-b8ea-5a9f5238b02b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 400, 3)]          0         \n","                                                                 \n"," lstm (LSTM)                 (None, 50)                10800     \n","                                                                 \n"," dense (Dense)               (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 10,851\n","Trainable params: 10,851\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["inputs = Input(shape=(400, 3))\n","lstm = LSTM(50, activation='relu')(inputs)\n","outputs = Dense(1)(lstm)\n","model = Model(inputs=inputs, outputs=outputs)\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"TKZdW_00ovaI"},"source":["In this case, the number of parameters of this LSTM layer can be calculated as: $4*(3+50+1)*50=10800$"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Output shape (None, 50)\n","10800\n","****************************************************************************************************\n","Output shape (None, 50)\n","10600\n","****************************************************************************************************\n","Output shape (None, 10, 50)\n","10800\n","****************************************************************************************************\n","Output shape [(None, 50), (None, 50), (None, 50)]\n","10800\n","****************************************************************************************************\n","Output shape [(None, 10, 50), (None, 50), (None, 50)]\n","10800\n","****************************************************************************************************\n"]}],"source":["def gen_lstm_model(lstm_param=LSTM(50)):\n","    inputs = Input(shape=(10, 3))\n","    lstm = lstm_param(inputs)\n","    # outputs = Dense(1)(lstm)\n","    model = Model(inputs=inputs, outputs=lstm)\n","    # model.summary()\n","    print('Output shape', model.output_shape)\n","    print(model.count_params())\n","    print('*'*100)\n","\n","gen_lstm_model(LSTM(50))\n","# use_bias: wheter the model uses a bias vector b: y = Wx + b\n","gen_lstm_model(LSTM(50, use_bias=False))\n","# return_sequences: return output (time_steps, units), output at each timestamp\n","gen_lstm_model(LSTM(50, return_sequences=True))\n","# return_states: return [output (units), state_h (units), state_c (units)]. In this case, state_h == output\n","gen_lstm_model(LSTM(50, return_state=True))\n","# return_sequences and return_states: \n","# return [output (time_steps, units), state_h (units), state_c (units)]. In this case, state_h == output[0,-1]\n","gen_lstm_model(LSTM(50, return_state=True, return_sequences=True))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor([[0.19843383 0.24309134]], shape=(1, 2), dtype=float32)\n","--------------------------------------------------------------------------------\n","tf.Tensor([[0.26354963 0.0401829 ]], shape=(1, 2), dtype=float32)\n","--------------------------------------------------------------------------------\n","tf.Tensor(\n","[[[ 0.0546216  -0.02551219]\n","  [ 0.00309311  0.00942754]\n","  [-0.06628668  0.16456468]]], shape=(1, 3, 2), dtype=float32)\n","--------------------------------------------------------------------------------\n","tf.Tensor([[-0.05335176  0.18356399]], shape=(1, 2), dtype=float32)\n","tf.Tensor([[-0.05335176  0.18356399]], shape=(1, 2), dtype=float32)\n","tf.Tensor([[-0.21267909  0.26048866]], shape=(1, 2), dtype=float32)\n","--------------------------------------------------------------------------------\n","tf.Tensor(\n","[[[-0.03435385 -0.00614802]\n","  [ 0.00335012 -0.00221255]\n","  [ 0.18249846  0.02452812]]], shape=(1, 3, 2), dtype=float32)\n","tf.Tensor([[0.18249846 0.02452812]], shape=(1, 2), dtype=float32)\n","tf.Tensor([[0.33608383 0.07505616]], shape=(1, 2), dtype=float32)\n"]}],"source":["# inputs (n_samples, n_time_steps, feature_vector)\n","inputs = tf.random.normal([1,3,1])\n","print(LSTM(2)(inputs))\n","print('-'*80)\n","print(LSTM(2, use_bias = False)(inputs))\n","print('-'*80)\n","print(LSTM(2, return_sequences=True)(inputs))\n","print('-'*80)\n","print(*LSTM(2, return_state=True)(inputs), sep='\\n')\n","print('-'*80)\n","print(*LSTM(2, return_state=True, return_sequences=True)(inputs), sep='\\n')"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_12 (LSTM)              (None, 10, 64)            17408     \n","                                                                 \n"," time_distributed (TimeDistr  (None, 10, 2)            130       \n"," ibuted)                                                         \n","                                                                 \n","=================================================================\n","Total params: 17,538\n","Trainable params: 17,538\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = Sequential()\n","model.add(Input(shape=(10, 3)))\n","model.add(LSTM(64, return_sequences=True))\n","# TimeDistributed layer will perform aplly the SAME Dense(2) on each of the time steps\n","model.add(tf.keras.layers.TimeDistributed(Dense(2)))\n","\n","model.compile(optimizer='adam', loss='mse')\n","\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"JEvyu06Vyj6H"},"source":["**units** parameter refers to dimensionality of the output. Each LSTM cell (present at a given time_step) takes in input x and forms a hidden state vector a, the length of this hidden vector is what is called the **units** in LSTM.\n","\n","When **units** is increased, width of the network increase, increases the number of parameters thus takes longer to train. If the **units** is too large, it might lead to overfitting."]},{"cell_type":"markdown","metadata":{"id":"ABxfQoFVBeCF"},"source":["**use_bias** parameter in an LSTM layer is a boolean that determines whether the layer uses a bias vector.<br>\n","**use_bias** set to True can help the model fit the data better, but it also increases the number of parameters in the model, which can potentially lead to overfitting."]}],"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":0}
